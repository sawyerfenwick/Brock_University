{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce07bd0-6540-472a-8f94-394ec902c336",
   "metadata": {},
   "source": [
    "# Query Operators - Pipeline Query Processing Model\n",
    "\n",
    "This file contains all the operators of our system.\n",
    "\n",
    "You will need to add your code for some of the functions in each operator. You may create new functions if you wish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57e2a0e-6333-4bcd-8773-8159066783cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Executor:\n",
    "    \"\"\"\n",
    "    A class to  represent all executors in our system\n",
    "    This abstract Executor implements the pipelining tuple-at-a-time query processing model.\n",
    "    This is the base class from which all executors in the system engine inherit, and defines the minimal interface that all executors support.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    init():\n",
    "        initializes operator state and sets parameters\n",
    "    openOp():\n",
    "        opens the operator\n",
    "    getNext()\n",
    "        calls fetchNext() on its inputs processes and produces output tuple(s) \n",
    "        returns None when done\n",
    "    fetchNext()\n",
    "        Yield the next tuple from operator\n",
    "    closeOp():\n",
    "        cleans up (if any)\n",
    "    \"\"\"\n",
    "    def __init__(self, tx_context):\n",
    "        self.tx_context = tx_context\n",
    "    \n",
    "    def openOp(self):\n",
    "        self.open = True\n",
    "    \n",
    "    def closeOp(self):\n",
    "        self.open = False\n",
    "        \n",
    "    def getNext(self):\n",
    "        return self.fetchNext();\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "    def fetchNext(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09e91b0-c825-4700-ae27-cefbfaf8f051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SeqScanExecutor(Executor):\n",
    "    \"\"\"\n",
    "    The SeqScanExecutor executor executes a sequential table scan.\n",
    "    The sequential scan executor iterates over a table and return its tuples one-at-a-time. \n",
    "    A sequential scan is specified by a SeqScanPlanNode. \n",
    "    The plan node specifies which table to iterate over. \n",
    "    The plan node may also contain a predicate; if a tuple does not satisfy the predicate, it is skipped over.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        plan: PlanNode\n",
    "            plan to be executed\n",
    "        tx_context: Context\n",
    "            context of the transaction executing the query\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    init():\n",
    "        initializes the sequential scan\n",
    "    openOp():\n",
    "        opens the operator\n",
    "    getNext()\n",
    "        calls fetchNext() on its inputs processes and produces output tuple(s) \n",
    "        returns None when done\n",
    "    fetchNext()\n",
    "        Yield the next tuple from the sequential scan.\n",
    "    closeOp():\n",
    "        cleans up (if any)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tx_context, plan): \n",
    "        super().__init__(tx_context)\n",
    "        self.plan = plan\n",
    "        self.dbFileIterator = self.tx_context.getCatalog().getTable(self.plan.getTableID()).getDatabaseFile().getIterator()\n",
    "        \n",
    "    def openOp(self):\n",
    "        super().openOp()\n",
    "        self.dbFileIterator.openIt()\n",
    "        self.next_tuple = self.dbFileIterator.getNext()\n",
    "        \n",
    "    def closeOp(self):\n",
    "        super().closeOp()\n",
    "        self.dbFileIterator.closeIt()\n",
    "\n",
    "    def reset(self):\n",
    "        self.dbFileIterator.resetIt()\n",
    "        self.next_tuple = self.dbFileIterator.getNext()\n",
    "    \n",
    "    def fetchNext(self):\n",
    "        #This function returns the next tuple from the scan, or None when it is done\n",
    "        #You will want to make use of the predicate in the sequential scan plan node. \n",
    "        #The ouput of sequential scan should be the matched tuples. Please make sure you understand the getNext function in the base Executor class\n",
    "        \n",
    "        #ADD YOUR CODE HERE\n",
    "        predicate = self.plan.getPredicate()\n",
    "        table_id = self.plan.getTableID()\n",
    "        iterator = self.tx_context.getCatalog().getTable(table_id).getDatabaseFile().getIterator()\n",
    "        columns = self.tx_context.getCatalog().getTable(table_id).getSchema().getColumns()\n",
    "        if predicate is None:\n",
    "            next_tuple = self.next_tuple\n",
    "            self.next_tuple = iterator.getNext()\n",
    "            return next_tuple\n",
    "        else:\n",
    "            field = predicate.field\n",
    "            operand = predicate.operand\n",
    "            index = columns.index(field)\n",
    "            while predicate.compare(self.next_tuple[index],operand) is False:\n",
    "                self.next_tuple = iterator.getNext()\n",
    "                if self.next_tuple is None:\n",
    "                    return None\n",
    "            next_tuple = self.next_tuple\n",
    "            self.next_tuple = iterator.getNext()\n",
    "            return next_tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fd9c06-9782-4ff1-8f7a-77d18cdf76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedLoopJoinExecutor(Executor):\n",
    "    \"\"\"\n",
    "    NestedLoopJoinExecutor executes a nested-loop JOIN on two tables.\n",
    "    The nested loop join executor iterates over the two children table and return its tuples one-at-a-time. \n",
    "    A sequential scan is specified by a NestedLoopJoinPlanNode. \n",
    "    The plan node specifies which tables to iterate over. \n",
    "    The plan node may also contain a predicate; if a tuple does not satisfy the join predicate, it is skipped over.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        plan: PlanNode\n",
    "            plan to be executed\n",
    "        tx_context: Context\n",
    "            context of the transaction executing the query\n",
    "        left_executor: Executor\n",
    "            the child executor that produces tuple for the left side of join\n",
    "        right_executor: Executor\n",
    "            the child executor that produces tuple for the right side of join\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    init():\n",
    "        initializes the sequential scan\n",
    "    openOp():\n",
    "        opens the operator\n",
    "    getNext()\n",
    "        calls fetchNext() on its inputs processes and produces output tuple(s) \n",
    "        returns None when done\n",
    "    fetchNext()\n",
    "        Yield the next tuple from the join.\n",
    "    closeOp():\n",
    "        cleans up (if any)\n",
    "    \"\"\"\n",
    "    def __init__(self, tx_context, plan, left_executor, right_executor):\n",
    "        super().__init__(tx_context)\n",
    "        self.left_executor = left_executor\n",
    "        self.right_executor = right_executor\n",
    "        self.plan = plan\n",
    "        \n",
    "    def openOp(self):\n",
    "        super().openOp()\n",
    "        self.left_executor.openOp()\n",
    "        self.right_executor.openOp()\n",
    "        \n",
    "        self.right_tuple =  self.right_executor.getNext()\n",
    "        self.left_tuple = self.left_executor.getNext()\n",
    "        \n",
    "    def closeOp(self):\n",
    "        super().closeOp()\n",
    "        self.left_executor.closeOp()\n",
    "        self.right_executor.closeOp()\n",
    "        \n",
    "    def fetchNext(self):\n",
    "        #This function returns the next tuple from joining (iterating over) the left table with the right one, or None when it is done\n",
    "        #The ouput of should be the matched combined tuples of the join condition (Predicate). Please make sure you understand the getNext function in the base Executor class\n",
    "        \n",
    "        #ADD YOUR CODE HERE\n",
    "        predicate = self.plan.getPredicate()\n",
    "        left_table_id = self.plan.getLeftPlan().getTableID()\n",
    "        left_table_columns = self.tx_context.getCatalog().getTable(left_table_id).getSchema().getColumns()\n",
    "        right_table_id = self.plan.getRightPlan().getTableID()\n",
    "        right_table_columns = self.tx_context.getCatalog().getTable(right_table_id).getSchema().getColumns()\n",
    "        operator = predicate.operator\n",
    "        field = predicate.field\n",
    "        operand = predicate.operand\n",
    "        \n",
    "        right_table_index = right_table_columns.index(field)\n",
    "        left_table_index = left_table_columns.index(field)\n",
    "        \n",
    "        if self.left_tuple is None or self.right_tuple is None:\n",
    "            return None \n",
    "        \n",
    "        while predicate.compare(self.left_tuple[left_table_index], self.right_tuple[right_table_index]) is False:\n",
    "            self.right_tuple = self.right_executor.getNext()\n",
    "            if self.right_tuple is None:\n",
    "                self.getNextLeftTuple()\n",
    "                if self.left_tuple is None:\n",
    "                    return None\n",
    "                self.resetRightTuple()\n",
    "        next_tuple = self.left_tuple + self.right_tuple\n",
    "        self.right_tuple = self.right_executor.getNext()\n",
    "        return next_tuple\n",
    "    \n",
    "    def resetRightTuple(self): \n",
    "        self.right_executor.reset()\n",
    "        self.right_tuple =  self.right_executor.getNext()\n",
    "    \n",
    "    def getNextLeftTuple(self):\n",
    "        self.left_tuple = self.left_executor.getNext()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44368449-91cf-4abb-92bc-87741123d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#Class to keep the aggregates of each \"group_by\" map\n",
    "class AggregationInfo():\n",
    "    def __init__(self):\n",
    "        self.cnt = 0\n",
    "        self.sum = 0\n",
    "        self.max = -sys.maxsize -1\n",
    "        self.min = sys.maxsize\n",
    "        \n",
    "    def getCount(self):\n",
    "        return self.cnt\n",
    "    \n",
    "    def getSum(self):\n",
    "        return self.sum\n",
    "    \n",
    "    def getMax(self):\n",
    "        return self.max\n",
    "    \n",
    "    def getMin(self):\n",
    "        return self.min\n",
    "    \n",
    "    def getAvg(self):\n",
    "        return self.sum/self.cnt\n",
    "    \n",
    "    def setCount(self, cnt):\n",
    "        self.cnt = cnt\n",
    "    \n",
    "    def setSum(self, sum):\n",
    "        self.sum = sum\n",
    "    \n",
    "    def setMax(self, max):\n",
    "        self.max = max\n",
    "    \n",
    "    def setMin(self, min):\n",
    "        self.min = min\n",
    "    \n",
    "\n",
    "class AggregationExecutor(Executor):\n",
    "    \"\"\"\n",
    "    AggregationExecutor executes an aggregation operation (e.g. COUNT, SUM, MIN, MAX) over the tuples produced by a child executor.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        plan: PlanNode\n",
    "            plan to be executed\n",
    "        tx_context: Context\n",
    "            context of the transaction executing the query\n",
    "        group_map: dict\n",
    "            maps the aggregation value for each group by attribute\n",
    "    Methods\n",
    "    -------\n",
    "    init():\n",
    "        initializes the sequential scan\n",
    "    openOp():\n",
    "        opens the operator\n",
    "    getNext()\n",
    "        calls fetchNext() on its inputs processes and produces output tuple(s) \n",
    "        returns None when done\n",
    "    fetchNext()\n",
    "        return the results of the aggregate\n",
    "    closeOp():\n",
    "        cleans up (if any)\n",
    "    \"\"\"\n",
    "    def __init__(self, tx_context, plan, child_executor):\n",
    "        super().__init__(tx_context)\n",
    "        self.child_executor = child_executor\n",
    "        self.plan = plan \n",
    "        self.group_map= {} #key,value     \n",
    "       \n",
    "    def openOp(self):\n",
    "        self.child_executor.openOp()\n",
    "        super().openOp()\n",
    "        self.done = False\n",
    "        \n",
    "    def closeOp(self):\n",
    "        super().closeOp()\n",
    "        self.child_executor.closeOp()\n",
    "        \n",
    "    def fetchNext(self):\n",
    "        #ADD YOUR CODE HERE\n",
    "        print('aggregation at', self.plan.getAggregateAt())\n",
    "        print('child plan', self.plan.getChildPlan().getType())\n",
    "        print('aggregation type', self.plan.getAggregateType())\n",
    "        print('group by', self.plan.getGroupByAt())\n",
    "        next_tuple = self.child_executor.fetchNext()\n",
    "        if next_tuple is not None:\n",
    "            self.insert(next_tuple[0],next_tuple[5])\n",
    "        results = self.group_map\n",
    "        return results\n",
    "        \n",
    "    def aggregate(self, key, value):\n",
    "        if (key != None):\n",
    "            agg_info = self.group_map.get(key)\n",
    "            agg_type = self.plan.getAggregateType()\n",
    "            if (agg_type ==\"MIN\"):\n",
    "                min_value = min(agg_info.getMin(), value)\n",
    "                agg_info.setMin(min_value)\n",
    "            if (agg_type ==\"MAX\"):\n",
    "                max_value = max(agg_info.getMax(), value)\n",
    "                agg_info.setMax(max_value)\n",
    "            if (agg_type ==\"SUM\"):\n",
    "                sum_value = agg_info.getSum() + value\n",
    "                agg_info.setSum(sum_value)\n",
    "            if (agg_type ==\"AVG\"):\n",
    "                sum_value = agg_info.getSum() + value\n",
    "                agg_info.setSum(sum_value)\n",
    "                cnt_value = agg_info.getCount() + 1\n",
    "                agg_info.setCount(cnt_value)\n",
    "            if (agg_type ==\"COUNT\"):\n",
    "                cnt_value = agg_info.getCount() + 1\n",
    "                agg_info.setCount(cnt_value)\n",
    "        \n",
    "    def insert(self, key, value):\n",
    "        if (key not in self.group_map):\n",
    "            aggInfo = AggregationInfo()\n",
    "            self.group_map[key] = aggInfo\n",
    "            \n",
    "        self.aggregate(key, value)\n",
    "        return\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
